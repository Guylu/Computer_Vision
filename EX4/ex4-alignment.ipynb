{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3096ad01d1be45cde139abf6562bf537",
     "grade": false,
     "grade_id": "cell-d8b9fae59d4812b1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Assignment 4: Image and Video Alignment\n",
    "\n",
    "## General Information\n",
    "**Submmision:** in pairs.\n",
    "\n",
    "## General Instructions\n",
    "\n",
    "The work you submit **must** run in the environment `wis-cv` which we provided.\n",
    "\n",
    "Do not change function headers. Where `**kwargs` is provided, use it to add any input you wish, and add it to the documentation.\n",
    "\n",
    "You may use the following [tutorial](http://cs231n.github.io/python-numpy-tutorial/) for Python.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise, you are asked to implement the 2D parametric estimation and alignment algorithm that was presented in class. The implementation should be for the case of a global 2D translation (i.e., a global image shift). Note that this is a special case of a homography, where\n",
    "$$ H = \n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & \\Delta x \\\\\n",
    "    0 & 1 & \\Delta y \\\\\n",
    "    0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The exercise has two main parts:\n",
    "\n",
    "* **Images:** Align an image with respect to a reference image.\n",
    "* **Videos:** Align a video with respect to a specific frame in the video. Use this to create a clean version of the frame, and to remove fast moving objects from the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple                       # for testing\n",
    "\n",
    "import numpy as np                                       # numpy\n",
    "import skimage.transform                                 # images\n",
    "from skimage.color import rgb2gray\n",
    "import matplotlib.pyplot as plt                          # plotting\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# ex4 imports\n",
    "from pyramids import pyramid_kernel, gaussian_reduce     # pyramids\n",
    "from pyramids import DEFAULT_DEPTH, DEFAULT_KERNEL       # default params\n",
    "from utils import imread, imwrite, imshow                # images\n",
    "from utils import vread, vwrite, vshow                   # video\n",
    "\n",
    "# your plot outputs will appear and be stored in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3635a07bd3f30dba99d6eef9e93a820",
     "grade": false,
     "grade_id": "cell-1f99401eddc4081e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 1 Images (50 points)\n",
    "\n",
    "In this part you will align an image with respect to a reference image, and test your results. You will implement the following methods: \n",
    "\n",
    "* **Align images**\n",
    "    * `find_shift()`\n",
    "    * `align_image()`\n",
    "* **Test align images**\n",
    "    * `root_mean_square_error()`\n",
    "    * `peak_signal_noise_ratio()`\n",
    "    * `error_map()`\n",
    "    * `test_align_image()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1749da179e507c264c4c3e07d7ca109b",
     "grade": false,
     "grade_id": "cell-6b0e3ad44822d5aa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.1 Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "daccd5262e4ec9c0f417832e977c9503",
     "grade": false,
     "grade_id": "cell-a2ef7a9f1d2d0192",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# PROVIDED FUNCTIONS\n",
    "def warp(image, shift):\n",
    "    \"\"\"Applies a shift on an image.\n",
    "    Fills the undefined areas with NaNs.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): image to be warped.\n",
    "        shift (np.ndarray): shift to warp with.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: warped image.\n",
    "    \"\"\"\n",
    "    inv_mat = np.eye(3)\n",
    "    inv_mat[0:2, 2] = -shift\n",
    "    return skimage.transform.warp(image, inv_mat, cval=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f75edb69ead44b1c28c66ed158f9f308",
     "grade": false,
     "grade_id": "cell-efcdc8404c676172",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### [Q1.1.1] Implement `find_shift()` (25 points)\n",
    "\n",
    "Find the shift between two images. Use the _Hierarchical Lucas & Kanade Method_:\n",
    "1. Start the process at the smallest pyramid level and iterate `iters` times per level.\n",
    "2. Use the shift from one level as an initialization for the next level. When doing this, remember to scale it accordingly.\n",
    "\n",
    "Technical details:\n",
    "* In order to perform the warping between images, you can use the provided `warp()` method.\n",
    "* You can use the provided pyramid methods imported at the beginning.\n",
    "* Use [`np.gradient`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.gradient.html) for taking the image derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7abe061149f210ab63a58c6659fb6565",
     "grade": true,
     "grade_id": "cell-d283f59edb92ed29",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_shift(image, reference, **kwargs):\n",
    "    \"\"\"Finds the best shift between `image` and `reference`.\n",
    "    \n",
    "    It should satisfy (up to small epsilon error):\n",
    "        warp(image, find_shift(image, reference)) == reference\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): the image to warp.\n",
    "        reference (np.ndarray): the image to warp to.\n",
    "        iters (int): number of iterations per pyramid-level (default: 5).\n",
    "        \n",
    "    Optional Args:\n",
    "        iters (int): number of iterations per pyramid-level (default: 5).\n",
    "        depth (int): depth of the pyramid (default: 5).\n",
    "        kernel (np.ndarray): kernel for the pyramid (default: with `a=0.375`).\n",
    "   \n",
    "    Your Args:\n",
    "        *TODO*: describe here your additional **kwargs variables.\n",
    "    \n",
    "    Returns:\n",
    "        results (dict): dictionary of results, with the following keys:\n",
    "                            results['shift']: an np.ndarray describing the shift in the form [dx, dy].\n",
    "                        may contain additional data (under other keys) for testing, e.g. for `test_image_align()`.       \n",
    "    \"\"\"\n",
    "    \n",
    "    # parse given arguments\n",
    "    iters = kwargs.pop('iters', 5)\n",
    "    depth = kwargs.pop('depth', DEFAULT_DEPTH)\n",
    "    kernel = kwargs.pop('kernel', DEFAULT_KERNEL)\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    results = {'shift_log': []}\n",
    "    reference_pyramid = gaussian_reduce(reference, kernel=kernel, depth=depth)\n",
    "    image_pyramid = gaussian_reduce(image, kernel=kernel, depth=depth)\n",
    "    \n",
    "    total_shift = np.zeros(2)\n",
    "    for layer in reversed(range(depth)):\n",
    "        ref = reference_pyramid[layer]\n",
    "        image = image_pyramid[layer]\n",
    "        \n",
    "        Iy, Ix, _ = np.gradient(image)\n",
    "\n",
    "        M = np.array([[(Ix**2).sum(), (Ix * Iy).sum()],\n",
    "                      [(Ix * Iy).sum(), (Iy**2).sum()]])\n",
    "        invM = np.linalg.pinv(M)\n",
    "\n",
    "        total_shift *= 2\n",
    "        for i in range(iters):\n",
    "            results['shift_log'].append(-total_shift * 2**layer)\n",
    "\n",
    "            current_ref = warp(ref, total_shift)  # Shift J to I (as was asked in class)\n",
    "            It = image - current_ref\n",
    "\n",
    "            b = - np.array([np.nansum(Ix * It), np.nansum(Iy * It)])            \n",
    "            \n",
    "            shift = invM @ b\n",
    "            total_shift += shift\n",
    "            \n",
    "\n",
    "    results['shift_log'].append(-total_shift)\n",
    "    results['shift'] = -total_shift  # The required shift is from I to J so a minus sign is needed\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e4289bdd4b40d340154664c96ac71ebc",
     "grade": true,
     "grade_id": "cell-43597f0bd802e1e3",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS #1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c38075e0cdf9cc859329d803acd45bbd",
     "grade": true,
     "grade_id": "cell-a0aa5c6d7eb5c698",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS #2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "823b26fb5020d2e69051e392572f4d45",
     "grade": true,
     "grade_id": "cell-404a421def598bdc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS #3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Q1.1.2] Implement `align_image()` (5 points)\n",
    "\n",
    "Align `image` to `reference`. Use the `find_shift()` method implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4c735040afc80a9194511e1a2dc9be5",
     "grade": true,
     "grade_id": "cell-dcc5a305632f63ce",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def align_image(image, reference, **kwargs):\n",
    "    \"\"\"Finds a shift between `image` and `reference` and applies it on `image`.\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): the image to warp.\n",
    "        reference (np.ndarray): the image to warp to.\n",
    "        \n",
    "    Optional Args:\n",
    "        iters (int): number of iterations per pyramid-level (default: 5).\n",
    "        depth (int): depth of the pyramid (default: 5).\n",
    "        kernel (np.ndarray): kernel for the pyramid (default: with `a=0.375`).\n",
    "    \n",
    "    Your Args:\n",
    "        *TODO*: describe here your additional **kwargs variables.\n",
    "    \n",
    "    Returns:\n",
    "        results (dict): dictionary of results, with the following keys:\n",
    "                            results['shift']: an np.ndarray describing the shift in the form [dx, dy].\n",
    "                            results['aligned_image']: `image` aligned to match `reference`.\n",
    "                        may contain additional data (under other keys) for testing, e.g. for `test_image_align()`.        \n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    results = find_shift(image, reference, **kwargs)\n",
    "    results['aligned_image'] = warp(image, results['shift'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4d1b9f724187a348ae9d9d7b9ed4a86",
     "grade": true,
     "grade_id": "cell-7c315a8b7e4c9fd0",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8c690d7b796538ee2c34663e96a2c5af",
     "grade": false,
     "grade_id": "cell-33ce176e269706ec",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1.2 Evaluation Utilities (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "851b8a33ed9c353ebcb9cdfb8431dc46",
     "grade": false,
     "grade_id": "cell-d4bf982a14ff183a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### [Q1.2.1] Implement the three following methods (10 points)\n",
    "\n",
    "These will be used to evaluate and visualize the operation of `align_image()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ed3a8d1229c7b1ea28e6861f9c3a2a6",
     "grade": true,
     "grade_id": "cell-0d7b9c42ca046aee",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def root_mean_square_error(image, reference):\n",
    "    \"\"\"Finds the root-mean-square error between `image` and `reference`.\n",
    "    \n",
    "    .. [1] https://en.wikipedia.org/wiki/Root-mean-square_deviation\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): image #1.\n",
    "        reference (np.ndarray): image #2.\n",
    "    \n",
    "    Returns:\n",
    "        rmse (float): root-mean-square error between `image` and `reference`.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return float(np.sqrt(np.nanmean((reference-image)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94c582ae9b0f901bfacd8bc8ee58234e",
     "grade": true,
     "grade_id": "cell-949b867aad394701",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def peak_signal_noise_ratio(image, reference, bounds=(0, 1)):\n",
    "    \"\"\"Finds the peak signal-to-noise ratio between `image` and `reference`.\n",
    "    \n",
    "    .. [1] https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): image #1.\n",
    "        reference (np.ndarray): image #2.\n",
    "        bounds (Tuple[float, float]): the minimal and maximal allowed pixel values.\n",
    "    \n",
    "    Returns:\n",
    "        psnr (float): peak signal-to-noise in dB.\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    MIN, MAX = bounds\n",
    "\n",
    "    image = np.clip(image, MIN, MAX)\n",
    "    reference = np.clip(reference, MIN, MAX)\n",
    "    rmse = root_mean_square_error(image, reference)\n",
    "    \n",
    "    return 20 * np.log10((MAX-MIN)/rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9be9bd1bce8d3ee56fb5a5f1d8f74202",
     "grade": true,
     "grade_id": "cell-c41ed18f6cc18e6a",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def error_map(image, reference, bounds=(0, 1), only_magnitude=False, zero_nans=False):\n",
    "    \"\"\"Creates a map of the difference between `image` and `reference`.\n",
    "        \n",
    "    Args:\n",
    "        image (np.ndarray): image #1.\n",
    "        reference (np.ndarray): image #2.\n",
    "        bounds (Tuple[float, float]): the minimal and maximal allowed pixel values.\n",
    "        only_magnitude (bool): whether `diff` should contain only the magnitude of `image - reference` (default: False).\n",
    "        zero_nans (bool): replace NaNs by zeros (default: False).\n",
    "        \n",
    "    Returns:\n",
    "        diff (np.ndarray): map of the differences between `image` and `reference`.\n",
    "        bounds (Tuple[float, float]): the valid bounds of diff.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    MIN, MAX = bounds\n",
    "    image = np.clip(image, MIN, MAX)\n",
    "    reference = np.clip(reference, MIN, MAX)\n",
    "    \n",
    "    diff = image - reference\n",
    "    diff_bounds = MIN-MAX, MAX-MIN\n",
    "\n",
    "    if only_magnitude:\n",
    "        diff = np.linalg.norm(diff, 2)\n",
    "        \n",
    "    if zero_nans:\n",
    "        diff = np.nan_to_num(diff)\n",
    "    \n",
    "    \n",
    "    return diff, diff_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6fa0150ed0832e1dc4864b9ee30fc15",
     "grade": true,
     "grade_id": "cell-2349fbd8a5991fb3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "693ab991834dea0dda1b6841dfe552f0",
     "grade": true,
     "grade_id": "cell-aeaee00796b14156",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93a07c9a70dbb5c99b146613a0c10ce3",
     "grade": true,
     "grade_id": "cell-aad4d797c4baf2cc",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a09d7abfa3488912e435c59561a77834",
     "grade": false,
     "grade_id": "cell-65d9202cbf334b22",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### [Q1.2.2] Implement `test_align_image()` (10 points)\n",
    "\n",
    "Implement `test_align_image()`, which will visualize the shifting and warping of a given image-refernce pair by `align_image()`. \n",
    "`test_align_image()` should create the following plots:\n",
    "\n",
    "* The original and the reference image, side by side\n",
    "* The original and aligned image, side by side\n",
    "* The difference images (original vs. reference, and original vs. aligned), side by side, with relevant RMSE values in the title.\n",
    "* A graph of the translation calculated in each iteration in each pyramid level. Note that the translation value needs to be scaled according to the appropriate pyramid level.\n",
    "\n",
    "You may use the functions `imshow_hbox()` and `imshow_tabs()` provided above.\n",
    "\n",
    "Your output should be similar to the following example:\n",
    "![example of test_align_image](docs/test_align_image.png \"example of test_align_image\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PROVIDED METOHDS\n",
    "def imshow_tabs(images, tab_names, titles=None, kwargs=None):\n",
    "    \"\"\"Normalize `images`, and show them in tabs with the given tab names.\n",
    "    \n",
    "    Args:\n",
    "        images (List[np.ndarray]): list of images to show.\n",
    "        tab_names (List[str]): list of image tab names.\n",
    "        bounds (List[Tuple[int, int]]): the minimal and maximal allowed pixel values for each image (if needed)      \n",
    "    \"\"\"\n",
    "    assert len(images) == len(tab_names)\n",
    "    if not isinstance(titles, (list, tuple)):\n",
    "        titles = [titles] * len(images)\n",
    "    assert len(images) == len(titles)\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "    n = len(images)\n",
    "    if isinstance(kwargs, dict):\n",
    "        kwargs = [kwargs for _ in range(n)]\n",
    "    outputs = [widgets.Output() for _ in range(n)]\n",
    "    boxes = widgets.Tab(children=outputs)\n",
    "    for i, (output, image, tab_name, title, kw) in enumerate(zip(outputs, images, tab_names, titles, kwargs)):\n",
    "        boxes.set_title(i, tab_name)\n",
    "        with output:\n",
    "            imshow(image, title=title, **kw)\n",
    "    \n",
    "    display(boxes)\n",
    "    \n",
    "def imshow_hbox(images, titles=None, kwargs=None):\n",
    "    \"\"\"Normalize `images`, and show them side-by-side.\n",
    "\n",
    "    Args:\n",
    "        images (List[np.ndarray]): list of images to show.\n",
    "        tab_names (List[str]): list of image tab names.\n",
    "        bounds (List[Tuple[int, int]]): the minimal and maximal allowed pixel values for each image (if needed)    \n",
    "    \"\"\"\n",
    "    if kwargs is None:\n",
    "        kwargs = {}\n",
    "    if not isinstance(titles, (list, tuple)):\n",
    "        titles = [titles] * len(images)\n",
    "    assert len(images) == len(titles)\n",
    "\n",
    "    n = len(images)\n",
    "    if isinstance(kwargs, dict):\n",
    "        kwargs = [kwargs for _ in range(n)]\n",
    "    outputs = [widgets.Output() for _ in range(n)]\n",
    "    boxes = widgets.HBox(children=outputs)\n",
    "    for i, (output, image, title, kw) in enumerate(zip(outputs, images, titles, kwargs)):\n",
    "        with output:\n",
    "            imshow(image, title=title, **kw)\n",
    "    \n",
    "    display(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10962693f6c29febabdf3df5eaae3c92",
     "grade": true,
     "grade_id": "cell-48db4a8638c58ace",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def test_align_image(path_image, path_reference, name, **kwargs):\n",
    "    \"\"\"Creates visualization of the shifting and warping of a given image-refernce pair.\n",
    "    \n",
    "    Args:\n",
    "        path_image (str): image's path.\n",
    "        path_reference (str): reference image's path.\n",
    "        name (str): name for the given image-reference instance.\n",
    "        \n",
    "    Optional Args:\n",
    "        iters (int): number of iterations per pyramid-level (default: 5).\n",
    "        depth (int): depth of the pyramid (default: 5).\n",
    "        kernel (np.ndarray): kernel for the pyramid (default: with `a=0.375`).\n",
    "   \n",
    "    Your Args:\n",
    "        *TODO*: describe here your additional **kwargs variables.        \n",
    "    \"\"\"\n",
    "    image = imread(path_image)\n",
    "    reference = imread(path_reference)\n",
    "    \n",
    "    results = align_image(image, reference, *kwargs)\n",
    "    aligned_image = results['aligned_image']\n",
    "    \n",
    "    original_error_map, original_bounds = error_map(image, reference)\n",
    "    aligned_error_map, aligned_bounds = error_map(aligned_image, reference)\n",
    "    \n",
    "    original_rmse = root_mean_square_error(image, reference)\n",
    "    aligned_rmse = root_mean_square_error(aligned_image, reference)\n",
    "    \n",
    "    imshow_hbox([image, reference], ['Image', 'Reference'])\n",
    "    imshow_hbox([image, aligned_image], ['Image', 'Aligned Image'])\n",
    "    imshow_hbox([original_error_map, aligned_error_map],\n",
    "                ['Difference Before Alignment: RMSE {}'.format(original_rmse),\n",
    "                 'Difference After Alignment: RMSE {}'.format(aligned_rmse)],\n",
    "               kwargs=[{\"bounds\": original_bounds}, {\"bounds\": aligned_bounds}])\n",
    "    \n",
    "    shift_log = np.array(results['shift_log'])\n",
    "\n",
    "    plt.plot(np.arange(0, len(shift_log)), shift_log[:, 0], '.-', label='dx') # Plot X\n",
    "    plt.plot(np.arange(0, len(shift_log)), shift_log[:, 1], '.-', label='dy') # Plot Y\n",
    "    \n",
    "    plt.xlabel('Iteration (N)')\n",
    "    plt.ylabel('Translation (pixels)')\n",
    "    plt.legend()\n",
    "    plt.title('Translation vs. Iterations')\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eadcc7538dad61e3b02ea8423455eb68",
     "grade": true,
     "grade_id": "cell-ba55675d7d84f202",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6295a2e013974e5984e1e00938f1d30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Output(), Output()), _titles={'0': 'Airport', '1': 'Parachute'})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ImagePair = namedtuple(\"ImagePair\", \"name path_image path_reference\")\n",
    "\n",
    "examples = [\n",
    "    ImagePair(\"Airport\", \"data/pairs/airport/01.jpg\", \"data/pairs/airport/02.jpg\"),\n",
    "    ImagePair(\"Parachute\", \"data/pairs/parachute/01.jpg\", \"data/pairs/parachute/02.jpg\")\n",
    "]\n",
    "\n",
    "canvas_list = widgets.Accordion(children=[widgets.Output() for _ in range(len(examples))])\n",
    "for i, (example, canvas) in enumerate(zip(examples, canvas_list.children)):\n",
    "    canvas_list.set_title(i, example.name)\n",
    "    with canvas:\n",
    "        test_align_image(example.path_image, example.path_reference, example.name)\n",
    "display(canvas_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e38911a8b040822027cf5bbf9b2cf575",
     "grade": false,
     "grade_id": "cell-8043c9a48fdacfa5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## 2 Videos (50 points)\n",
    "\n",
    "In this part you will use the tool of image alignment to process videos. You will reduce noise of a video frame using information from other frames, and you will remove fast moving objects from a video.\n",
    "You will implement the following methods:\n",
    "* `align_video()`\n",
    "* `reduce_noise()`\n",
    "* `remove_dynamics()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "741cd0844e3909de24549e72d3d5a34e",
     "grade": false,
     "grade_id": "cell-e9b73540d33cb34f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.1 Core (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "542a70b5f13a4c28d16e1e1a5ebd9575",
     "grade": false,
     "grade_id": "cell-0d73c5e318a6edd2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### [Q2.1.1] Implement `align_video()` (15 points)\n",
    "\n",
    "In this part, you need to align a video according to a reference frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7494a9aa7cc19d56645fc387b739094b",
     "grade": true,
     "grade_id": "cell-ab693e2c93379a55",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def align_video(video, ref_idx, **kwargs):\n",
    "    \"\"\"Finds the shift between each frame in `video` to frame number `ref_idx`, and aligns all the frames to the reference frame.\n",
    "        \n",
    "    Args:\n",
    "        video (np.ndarray): the video to align.\n",
    "        ref_idx (int): index of the reference frame.\n",
    "        \n",
    "    Optional Args:\n",
    "        iters (int): number of iterations per pyramid-level (default: 5).\n",
    "        depth (int): depth of the pyramid (default: 5).\n",
    "        kernel (np.ndarray): kernel for the pyramid (default: with `a=0.375`).\n",
    "   \n",
    "    Your Args:\n",
    "        *TODO*: describe here your additional **kwargs variables.\n",
    "    \n",
    "    Returns:\n",
    "        results (dict): dictionary of results, with the following keys:       \n",
    "                            results['shift_list']: list of shifts between frames and the reference frame.\n",
    "                            results['aligned_video']: `video` aligned w.r.t the reference frame.\n",
    "                        may contain additional data (under other keys).\n",
    "    \"\"\"\n",
    "\n",
    "# #   NAIVE SOLUTION:\n",
    "#     results = {}\n",
    "#     reference_frame = video[ref_idx,:,:,:]\n",
    "    \n",
    "#     results['aligned_video'] = np.zeros_like(video)\n",
    "#     results['shift_list'] = []\n",
    "#     for i, frame in enumerate(video):\n",
    "#         res = align_image(frame,reference_frame) \n",
    "#         results['shift_list'].append(res['shift'])\n",
    "#         results['aligned_video'][i,:,:,:] = res['aligned_image']\n",
    "        \n",
    "#     return results\n",
    "\n",
    "\n",
    "    results = {}\n",
    "    shifts = []\n",
    "    results['aligned_video'] = np.zeros_like(video)\n",
    "    results['shift_list'] = []\n",
    "    \n",
    "    for i in range(video.shape[0]-1):\n",
    "        res = find_shift(video[i,:,:,:],video[i+1,:,:,:],**kwargs) \n",
    "        shifts.append(res['shift'])\n",
    "    \n",
    "    shifts_np = np.stack(shifts)\n",
    "    \n",
    "    # backwards loop from ref to 0 frame\n",
    "    for i in range(0, ref_idx):\n",
    "        results['shift_list'].append(np.sum(shifts_np[i:ref_idx,:],axis=0))\n",
    "\n",
    "   \n",
    "    # forwards loop from ref to end frame\n",
    "    for i in range(ref_idx, video.shape[0]):\n",
    "        results['shift_list'].append(-np.sum(shifts_np[ref_idx:i,:],axis=0))\n",
    "\n",
    "    # alinging video frames with respect to summed shifts\n",
    "    for i in range(video.shape[0]):\n",
    "        results['aligned_video'][i,:,:,:] = warp(video[i,:,:,:], results['shift_list'][i])\n",
    "    return results\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36faa626330c7e1414d165d00dedc72f",
     "grade": true,
     "grade_id": "cell-b8a296aa6d0d3356",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\guylu\\anaconda3\\envs\\wis-cv\\lib\\site-packages\\skimage\\transform\\_warps.py:655: RuntimeWarning: invalid value encountered in less_equal\n",
      "  (min_val <= cval <= max_val))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946da482323a4587b03ffbe93b740dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6890ba522cf9412b8e0cceb0a7da1519",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video, meta = vread(\"data/video_with_michal.avi\")\n",
    "results = align_video(video, ref_idx=video.shape[0]//2)\n",
    "\n",
    "vshow(video, title=\"Original Video\", meta=meta)\n",
    "vshow(results['aligned_video'], title=\"Aligned Video\", fname=\"results/align_video/aligned_video.mp4\", meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e5a1c36876d438ec9f7d4733ab2d02ce",
     "grade": true,
     "grade_id": "cell-5de0b05a08f7879f",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a199982dfe44b56dfada0902ecbe2370",
     "grade": true,
     "grade_id": "cell-0f0507addc1ddcc8",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS #2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6b9953a59322e19066666f0ee0a0c916",
     "grade": false,
     "grade_id": "cell-bde589d67122803a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### [Q2.1.2] Theoretical Question (5 points)\n",
    "Image alignment doesn't always work well when the shift is too big. How can you use additional information from the video to improve the accuracy of such \"far\" alignments?\n",
    "Make sure to implement this improvement in `align_video()`. You may check it by looking at the alignment of the first/last frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9767d8c4489ccf6266e13365b5cedacf",
     "grade": true,
     "grade_id": "cell-0cbe6ea6308f871b",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "A naive implementation of the algorithm would be to align each frame of the video to the reference frame independently.\n",
    "This solution is indeed capable of aligning the video, yet it struggles when it comes to frames that are far away.\n",
    "To remedy this we can introduce additional information from the rest of the frames in the video - take into account all intermidiate transformations from each frame to the reference frame and compose them (sum them up).\n",
    "This way we get the total transformation from each frame to the reference frame with which can warp the frames to obtain the aligned video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "db01f0dd2a359ec41f3b2a9d08531860",
     "grade": false,
     "grade_id": "cell-96608a57da502e3f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.2 Noise Reduction (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fc0dd9c178c1209163421b419f12cb28",
     "grade": false,
     "grade_id": "cell-f0a8637b7fa7dcc6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### [Q2.2.1] Implement `reduce_noise()` (10 points)\n",
    "\n",
    "In this section we provide you with a noisy movie. The movie is of a static scene and is corrupted with noise.\n",
    "When having multiple repetitions of the same pixel in different frame, we can remove the noise by taking the median of this pixel across all frames.\n",
    "\n",
    "Technical details:\n",
    "* read about [`np.nanmedian()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.nanmedian.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8d8a12effd286978ef3ebf7ad881068",
     "grade": true,
     "grade_id": "cell-45edc7ed5f94b8d9",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def reduce_noise(video, ref_idx, **kwargs):\n",
    "    \"\"\"Generates a clean version of a frame in a video, using information from other frames.\n",
    "    \n",
    "    Args:\n",
    "        video (np.ndarray): the video to align.\n",
    "        ref_idx (int): index of the reference frame.\n",
    "\n",
    "    Your Args:\n",
    "        *TODO*: describe here your additional **kwargs variables.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: cleaned image.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    results = align_video(video, ref_idx, **kwargs)\n",
    "    aligned_video = results['aligned_video']\n",
    "    median_frame = np.nanmedian(aligned_video,axis=0)\n",
    "    return median_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "99d2f3c6e0b8472db6258e7961d41bb4",
     "grade": true,
     "grade_id": "cell-5bbfc477cc97bcbc",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96fda864ca8b9d05a963a8bbeccb1319",
     "grade": true,
     "grade_id": "cell-ad02cc17349d88d4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7eff171c84b4dc688f11050513c3c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf72b1c8d6845f7b5d5feee15963061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1beab3e35c3d427993139e0698918702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4988a8724a5b493588f5f02515a657d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "noisy_video, meta = vread(\"data/noisy_video.avi\")\n",
    "\n",
    "noisy_scene = noisy_video[noisy_video.shape[0]//2]\n",
    "clean_scene = reduce_noise(noisy_video, ref_idx=noisy_video.shape[0]//2)\n",
    "\n",
    "vshow(noisy_video, title=\"Noisy Video\", meta=meta)\n",
    "imshow(noisy_scene, title=\"Noisy Image\")\n",
    "imshow(clean_scene, title=\"Clean Image\", fname=\"results/noise_reduction/clean_scene.png\")\n",
    "imshow(*error_map(clean_scene, noisy_scene), title=\"Noise\", fname=\"results/noise_reduction/noise.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5be045fefcf094bd28e87fe5dbc060c3",
     "grade": false,
     "grade_id": "cell-e771e8cd7e4cdcf8",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### [Q2.2.2] Theoretical question (5 points)\n",
    "Why do you think you were asked to use median rather than mean for the noise reduction?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28fb2f83a981d76a4d6ce1bcf1e614d0",
     "grade": true,
     "grade_id": "cell-e9c54a9bc6fdb885",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "The median is defined to be the value such that half of the data points are larger than it and half are less. \n",
    "The median is therefore susciptible only to the amount of the outliers in the sample (as oposed to their values), which is definitively small, therefore it should not dramatically affect the median value. \n",
    "The averge, however is susciptible to the outliers' values, which can really affect our results, due to extreme values (out of distribution).\n",
    "\n",
    "In our case we don't want noisy outliers to affect our result, and so we need to come up with with a measure that is robust to outliers - hence the use of the median as opposed to the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f1c72251e09b3fe99ace799644f468a",
     "grade": false,
     "grade_id": "cell-f0103616ec3de246",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2.3 Remove Dynamics (15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71249bade1cb2916e05455134540776c",
     "grade": false,
     "grade_id": "cell-e5b79b9c418d1cf2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### [Q2.3.1] Implement `remove_dynamics()` (10 points)\n",
    "\n",
    "In this section we provide you with a movie which includes two motions: (i) camera pan; and (ii) a walking professor.\n",
    "Applying alignment to the entire frame will lock on to the dominant motion (in this case the camera motion). Taking the median of each pixel across all frames would eliminate the walking professor from the entire movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0301ff4b5d50e6f7365676fd974dd483",
     "grade": true,
     "grade_id": "cell-a56aaa1895c8e8d4",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_dynamics(video, ref_idx, **kwargs):\n",
    "    \"\"\"Generates a clean version of a video, removing fast moving objects (and also noise).\n",
    "    \n",
    "    Args:\n",
    "        video (np.ndarray): the video to align.\n",
    "        ref_idx (int): index of the reference frame.\n",
    "\n",
    "    Your Args:\n",
    "        *TODO*: describe here your additional **kwargs variables.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: cleaned video.\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    removed_dyn_video = np.zeros_like(video)\n",
    "    for i in range(video.shape[0]):\n",
    "        removed_dyn_video[i:,:,:] = reduce_noise(video, i, **kwargs)\n",
    "        \n",
    "    return removed_dyn_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "317e9d80284ae76929ea022ec904281a",
     "grade": true,
     "grade_id": "cell-d7a0c93c35e734bf",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### HIDDEN AUTOMATIC TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4734f9ad9f47522034e948d8f9ac238",
     "grade": true,
     "grade_id": "cell-5d09d1455713524c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6777bc0385ee455daa307c69958d45f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f73e57ea7804a4a9f072c34185cc6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_with_michal, meta = vread(\"data/video_with_michal.avi\")\n",
    "video_without_michal = remove_dynamics(video_with_michal, ref_idx=video_with_michal.shape[0]//2)\n",
    "\n",
    "vshow(video_with_michal, title=\"With Michal\", meta=meta)\n",
    "vshow(video_without_michal, title=\"Without Michal\", fname=\"results/remove_dynamics/video_without_michal.mp4\", meta=meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e94d9e9f6b7e97ffd9ee30ad3c5165c7",
     "grade": false,
     "grade_id": "cell-4adae2439fc4ee78",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "#### [Q2.3.2] Theoretical Question\n",
    "Do you observe any artifacts in the output video (_without Michal_)? What is the cause of these artifacts? Can they be fixed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bad632252dec8ea598de110ec287776",
     "grade": true,
     "grade_id": "cell-481814ab82cf04f4",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "Indeed we do see some artifacts. When the camera shifts its view to the left, we sudenlly see a vertical line separating the left side of the room (where the shelf is) from the right (where the cubicle is). We conjecture that the different exposure of the camera between the frames is to blame - since we noticed that the contrast changes throughout the video, resulting in change of intesities. \n",
    "\n",
    "To amend this, we suggest using pyramid blending technique, as was implemented in EX2. We would use every consecutive pair of frames and use the shifts between them to produce a separating mask (NaN in one image implies the pixes belonging to the other), and apply the pyramid blending algorithm consecutively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}